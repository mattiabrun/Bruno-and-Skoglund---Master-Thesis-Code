{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import fitz  #PyMuPDF\n",
    "\n",
    "def pdf_to_text(file_path):\n",
    "    with fitz.open(file_path) as pdf:\n",
    "        text = ''\n",
    "        for page in pdf:\n",
    "            text += page.get_text(\"text\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pdf_directory_pwc = #Your directory to PwC folder\n",
    "pdf_directory_ey = #Your directory to EY folder\n",
    "pdf_directory_deloitte = #Your directory to Deloitte folder\n",
    "pdf_directory_kpmg = #Your directory to KPMG folder\n",
    "file_list_pwc = os.listdir(pdf_directory_pwc)\n",
    "file_list_ey = os.listdir(pdf_directory_ey)\n",
    "file_list_deloitte = os.listdir(pdf_directory_deloitte)\n",
    "file_list_kpmg = os.listdir(pdf_directory_kpmg)\n",
    "\n",
    "data_pwc = []\n",
    "data_ey = []\n",
    "data_deloitte = []\n",
    "data_kpmg = []\n",
    "\n",
    "#Convert all PwC files\n",
    "for file_name in file_list_pwc:\n",
    "    if file_name.endswith('.pdf'):\n",
    "        file_path = os.path.join(pdf_directory_pwc, file_name)\n",
    "        year = int(file_name.split('_')[-1].split('.')[-2]) \n",
    "        firm = file_name.split('_')[0]\n",
    "        title = file_name.split('_')[1]\n",
    "\n",
    "        text = pdf_to_text(file_path)\n",
    "        data_pwc.append({'firm': firm, 'year': year, 'title': title, 'text': text})\n",
    "        print('File completed')\n",
    "\n",
    "print('PwC Completed')\n",
    "\n",
    "\n",
    "#Convert all EY files\n",
    "for file_name in file_list_ey:\n",
    "    if file_name.endswith('.pdf'):\n",
    "        file_path = os.path.join(pdf_directory_ey, file_name)\n",
    "        year = int(file_name.split('_')[-1].split('.')[-2]) \n",
    "        firm = file_name.split('_')[0]\n",
    "        title = file_name.split('_')[1]\n",
    "\n",
    "        text = pdf_to_text(file_path)\n",
    "        data_ey.append({'firm': firm, 'year': year, 'title': title, 'text': text})\n",
    "        print('File completed')\n",
    "\n",
    "print('EY Completed')\n",
    "\n",
    "#Convert all Deloitte files\n",
    "for file_name in file_list_deloitte:\n",
    "    if file_name.endswith('.pdf'):\n",
    "        file_path = os.path.join(pdf_directory_deloitte, file_name)\n",
    "        year = int(file_name.split('_')[-1].split('.')[-2]) \n",
    "        firm = file_name.split('_')[0]\n",
    "        title = file_name.split('_')[1]\n",
    "\n",
    "        text = pdf_to_text(file_path)\n",
    "        data_deloitte.append({'firm': firm, 'year': year, 'title': title, 'text': text})\n",
    "        print('File completed')\n",
    "\n",
    "print('Deloitte Completed')\n",
    "\n",
    "#Convert all KPMG files\n",
    "for file_name in file_list_kpmg:\n",
    "    if file_name.endswith('.pdf'):\n",
    "        file_path = os.path.join(pdf_directory_kpmg, file_name)\n",
    "        year = int(file_name.split('_')[-1].split('.')[-2]) \n",
    "        firm = file_name.split('_')[0]\n",
    "        title = file_name.split('_')[1]\n",
    "\n",
    "        text = pdf_to_text(file_path)\n",
    "        data_kpmg.append({'firm': firm, 'year': year, 'title': title, 'text': text})\n",
    "        print('File completed')\n",
    "\n",
    "print('KPMG Completed')\n",
    "\n",
    "#Make dataframes\n",
    "df_pwc = pd.DataFrame(data_pwc)\n",
    "df_ey = pd.DataFrame(data_ey)\n",
    "df_deloitte = pd.DataFrame(data_deloitte)\n",
    "df_kpmg = pd.DataFrame(data_kpmg)\n",
    "\n",
    "#Save as CSV file\n",
    "#Create the folder if it doesn't exist\n",
    "if not os.path.exists('CSVFiles'):\n",
    "    os.makedirs('CSVFiles')\n",
    "df_pwc.to_csv('CSVFiles/df_pwc_2.csv', index=False)\n",
    "df_ey.to_csv('CSVFiles/df_ey_2.csv', index=False)\n",
    "df_deloitte.to_csv('CSVFiles/df_deloitte_2.csv', index=False)\n",
    "df_kpmg.to_csv('CSVFiles/df_kpmg_2.csv', index=False)\n",
    "\n",
    "#Convert CSif os.path.exists('CSVFiles'):\n",
    "if os.path.exists('CSVFiles'):    \n",
    "    df_pwc = pd.read_csv('CSVFiles/df_pwc_2.csv')\n",
    "    df_ey = pd.read_csv('CSVFiles/df_ey_2.csv')\n",
    "    df_deloitte = pd.read_csv('CSVFiles/df_deloitte_2.csv')\n",
    "    df_kpmg = pd.read_csv('CSVFiles/df_kpmg_2.csv')\n",
    "else:\n",
    "    print(\"CSVFiles directory does not exist.\")\n",
    "\n",
    "df_pwc[\"text\"] = df_pwc[\"text\"].astype(str)\n",
    "df_ey[\"text\"] = df_ey[\"text\"].astype(str)\n",
    "df_deloitte[\"text\"] = df_deloitte[\"text\"].astype(str)\n",
    "df_kpmg[\"text\"] = df_kpmg[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "\n",
    "#Set the NLTK data path to your desired directory\n",
    "nltk_data_path = os.path.join(os.path.expanduser(\"~\"), \"nltk_data\")\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "#Download required NLTK resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "# Define categories and their keywords\n",
    "categories = {\n",
    "    'benefit': ['benefit', 'beneficial', 'advantage', 'advantageous', 'potential', 'gain', 'profit', 'perk', 'enhancement', 'improvement', 'strategy', 'competitive', 'efficiency', \n",
    "                 'effective', 'effectiveness', 'innovation', 'value-added', 'value', 'productivity', 'saving', 'optimization', 'satisfaction', 'flexibility', \n",
    "                 'progress', 'revenue', 'success', 'successfully', 'edge', 'upside', 'breakthrough', 'prosperity', 'favorable', 'merit', 'favor',\n",
    "                 'privilege', 'bonus', 'usefulness'],\n",
    "    'risk': ['risk', 'challenge', 'uncertainty', 'danger', 'obstacle', 'difficult', 'difficulty', 'adversity', 'pitfall', 'complexity', 'disruption', 'hazard', 'hurdle', \n",
    "              'impediment', 'downside', 'complication', 'barrier', 'setback', 'obstruction', 'drawback', 'threat', 'peril', 'trouble', 'limitation', 'cybersecurity', 'privacy', \n",
    "              'security', 'vulnerability', 'cyberattack', 'breach', 'data', 'intrusion', 'exploitation', 'malware', 'encryption', 'authentication', 'attack', 'malicious', \n",
    "              'cyber', 'defense'],\n",
    "    'human-ai': ['collaboration', 'automation', 'adaptation', 'adaptability', 'learning', 'learn', 'skill', 'augmentation', 'empowerment', 'trust', 'employee', 'human', \n",
    "                 'resistance', 'training', 'cooperation', 'coexistence', 'synergy', 'resilience', 'work', 'people', 'interaction', 'acceptance'],\n",
    "    'ethical consideration' :['integrity', 'accountability', 'value', 'transparency', 'ethical', 'responsibility', 'responsible', 'trustworthiness', 'bias', 'discrimination', \n",
    "                              'morality', 'fairness', 'social', 'moral', 'ethicality', 'impartiality'],\n",
    "    'regulation': ['regulation', 'governance', 'directive', 'compliance', 'policy', 'standardization', 'rule', 'legislation', 'enforcement', 'standard', 'norm', 'authority', \n",
    "                   'legal', 'control', 'requirement', 'act', 'law', 'parliament', 'council', 'regulatory']\n",
    "}\n",
    "\n",
    "# Define a list of words to remove\n",
    "remove_list = []\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    #Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove digits and numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    for remove_str in remove_list:\n",
    "        text = text.replace(remove_str, \"\")\n",
    "        \n",
    "    #Remove punctuation and special characters\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    #Tokenize the text\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    #Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    #Perform lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "# Preprocess text in each dataframe\n",
    "df_pwc[\"processed_words\"] = df_pwc[\"text\"].apply(preprocess_text)\n",
    "df_ey[\"processed_words\"] = df_ey[\"text\"].apply(preprocess_text)\n",
    "df_deloitte[\"processed_words\"] = df_deloitte[\"text\"].apply(preprocess_text)\n",
    "df_kpmg[\"processed_words\"] = df_kpmg[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count keyword occurrences\n",
    "def count_keywords(words):\n",
    "    counts = {category: 0 for category in categories}\n",
    "    for word in words:\n",
    "        for category, keywords in categories.items():\n",
    "            if word in keywords:\n",
    "                counts[category] += 1\n",
    "    return counts\n",
    "\n",
    "# Function to categorize documents\n",
    "def categorize_document(counts):\n",
    "    max_category = \"\"\n",
    "    max_count = 0\n",
    "    for category, count in counts.items():\n",
    "        if count > max_count and category in categories:\n",
    "            max_count = count\n",
    "            max_category = category\n",
    "    return max_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count keyword occurrences and categorize documents\n",
    "for df in [df_pwc, df_ey, df_deloitte, df_kpmg]:\n",
    "    df['keyword_counts'] = df['processed_words'].apply(count_keywords)\n",
    "    df['total_words'] = df['processed_words'].apply(len)\n",
    "\n",
    "\n",
    "# Function to calculate category percentage\n",
    "def calculate_category_percentage(counts, total_words):\n",
    "    percentages = {category: (count / total_words) * 100 for category, count in counts.items()}\n",
    "    return percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "# Print PwC categorized documents as a table\n",
    "for df_name, df in [('PwC', df_pwc)]:\n",
    "    print(f\"Documents categorized for {df_name}:\")\n",
    "    table_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        category_percentages = calculate_category_percentage(row['keyword_counts'], row['total_words'])\n",
    "        row_data = [idx, row['firm'], row['title'], row['year']]\n",
    "        row_data.extend([f\"{category_percentages.get(category, 0):.2f}%\" for category in categories.keys()])\n",
    "        table_data.append(row_data)\n",
    "    headers = ['index', 'firm', 'title', 'year'] + [f'{category}' for category in categories.keys()]\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# Create a DataFrame from the tabulated data\n",
    "df_tabulate = pd.DataFrame(table_data, columns=headers)\n",
    "\n",
    "# Specify the path where you want to save the Excel file\n",
    "excel_file_path = 'C:/Users/bruno/OneDrive/Desktop/Master/Thesis/categorized_documents_pwc.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df_tabulate.to_excel(excel_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "# Print EY categorized documents as a table\n",
    "for df_name, df in [('EY', df_ey)]:\n",
    "    print(f\"Documents categorized for {df_name}:\")\n",
    "    table_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        category_percentages = calculate_category_percentage(row['keyword_counts'], row['total_words'])\n",
    "        row_data = [idx, row['firm'], row['title'], row['year']]\n",
    "        row_data.extend([f\"{category_percentages.get(category, 0):.2f}%\" for category in categories.keys()])\n",
    "        table_data.append(row_data)\n",
    "    headers = ['index', 'firm', 'title', 'year'] + [f'{category}' for category in categories.keys()]\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# Create a DataFrame from the tabulated data\n",
    "df_tabulate = pd.DataFrame(table_data, columns=headers)\n",
    "\n",
    "# Specify the path where you want to save the Excel file\n",
    "excel_file_path = 'C:/Users/bruno/OneDrive/Desktop/Master/Thesis/categorized_documents_ey.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df_tabulate.to_excel(excel_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "# Print Deloitte categorized documents as a table\n",
    "for df_name, df in [('Deloitte', df_deloitte)]:\n",
    "    print(f\"Documents categorized for {df_name}:\")\n",
    "    table_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        category_percentages = calculate_category_percentage(row['keyword_counts'], row['total_words'])\n",
    "        row_data = [idx, row['firm'], row['title'], row['year']]\n",
    "        row_data.extend([f\"{category_percentages.get(category, 0):.2f}%\" for category in categories.keys()])\n",
    "        table_data.append(row_data)\n",
    "    headers = ['index', 'firm', 'title', 'year'] + [f'{category}' for category in categories.keys()]\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# Create a DataFrame from the tabulated data\n",
    "df_tabulate = pd.DataFrame(table_data, columns=headers)\n",
    "\n",
    "# Specify the path where you want to save the Excel file\n",
    "excel_file_path = 'C:/Users/bruno/OneDrive/Desktop/Master/Thesis/categorized_documents_deloitte.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df_tabulate.to_excel(excel_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "# Print KPMG categorized documents as a table\n",
    "for df_name, df in [('KPMG', df_kpmg)]:\n",
    "    print(f\"Documents categorized for {df_name}:\")\n",
    "    table_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        category_percentages = calculate_category_percentage(row['keyword_counts'], row['total_words'])\n",
    "        row_data = [idx, row['firm'], row['title'], row['year']]\n",
    "        row_data.extend([f\"{category_percentages.get(category, 0):.2f}%\" for category in categories.keys()])\n",
    "        table_data.append(row_data)\n",
    "    headers = ['index', 'firm', 'title', 'year'] + [f'{category}' for category in categories.keys()]\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# Create a DataFrame from the tabulated data\n",
    "df_tabulate = pd.DataFrame(table_data, columns=headers)\n",
    "\n",
    "# Specify the path where you want to save the Excel file\n",
    "excel_file_path = 'C:/Users/bruno/OneDrive/Desktop/Master/Thesis/categorized_documents_kpmg.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df_tabulate.to_excel(excel_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
